#!/bin/bash
# Performance Improvements for codeEcho

# 1. Add resource limits to Docker Compose file
echo "Adding resource limits to Docker Compose"
cat << EOF > docker-compose.resource-limits.yml
version: '3'

services:
  codeecho-api:
    mem_limit: 1GB
    cpus: 1.0
    
  codeecho-ui:
    mem_limit: 512M
    cpus: 0.5
    
  codeecho-cli:
    mem_limit: 512M
    cpus: 0.5
    
  codeecho-db:
    mem_limit: 1GB
    cpus: 0.5
EOF

# 2. Implement improved git clone with depth limit
echo "Creating optimized git service implementation"
cat << 'EOF' > git_service_optimized.patch
--- a/infrastructure/git/git_service_impl.go
+++ b/infrastructure/git/git_service_impl.go
@@ -77,7 +77,10 @@ func (gs *GitServiceImpl) CloneRepository(repoURL string) (string, error) {
 
 	// Prepare clone options
 	cloneOptions := &git.CloneOptions{
-		URL:      repoURL,
+		URL:        repoURL,
+		Depth:      20,              // Only fetch recent commits initially
+		SingleBranch: true,          // Only clone the default branch
+		NoCheckout: false,           // We need the files
 		Progress: os.Stdout,
 	}
 
@@ -125,7 +128,15 @@ func (gs *GitServiceImpl) getCommitsFromHash(repoPath string, fromHash string) ([
 	var commitIter object.CommitIter
 	if fromHash == "" {
 		// Get all commits from HEAD
-		ref, err := repo.Head()
+		
+		// Set a maximum number of commits to process to avoid memory issues
+		maxCommits := 500
+		log.Printf("[git] Setting maximum commits to process: %d", maxCommits)
+		
+		// Use a counter to limit commits processed
+		commitCounter := 0
+		commitLimit := maxCommits
+		
+		ref, err := repo.Head() 
 		if err != nil {
 			return nil, fmt.Errorf("failed to get HEAD reference: %w", err)
 		}
@@ -151,6 +162,12 @@ func (gs *GitServiceImpl) getCommitsFromHash(repoPath string, fromHash string) ([
 		skipFirst = false
 		return nil
 	}
+	
+	// Stop processing if we hit the commit limit
+	commitCounter++
+	if commitCounter > commitLimit {
+		return fmt.Errorf("reached commit processing limit of %d", commitLimit)
+	}
 
 	// Get file changes for this commit
 	changes, err := gs.getCommitChanges(commit)
EOF

# 3. Optimize frontend polling
echo "Creating optimized frontend polling patch"
cat << 'EOF' > frontend_polling_optimized.patch
--- a/codeecho-ui/src/pages/Projects.js
+++ b/codeecho-ui/src/pages/Projects.js
@@ -31,6 +31,7 @@ const Projects = () => {
   const [analysisStartTimes, setAnalysisStartTimes] = useState({}); // { projectId: timestamp }
   const [nowTick, setNowTick] = useState(Date.now());
   const intervalRef = useRef(null); // project list polling
+  const pollingIntervalRef = useRef(4000); // Start with 4s, will increase over time
 
   useEffect(() => {
     // Initial data loading
@@ -114,12 +115,20 @@ const Projects = () => {
     const hasAnalyzing = currentlyAnalyzing.size > 0;
 
     // Project list polling
-    if (hasAnalyzing && !intervalRef.current) {
+    if (hasAnalyzing && !intervalRef.current) {      
+      // Implement exponential backoff for polling
+      const maxInterval = 30000; // Max 30 seconds
+      
       intervalRef.current = setInterval(async () => {
-        try { await api.getProjects(); } catch { /* ignore */ }
-      }, 4000);
+        try { 
+          await api.getProjects(); 
+          // Increase polling interval gradually
+          pollingIntervalRef.current = Math.min(pollingIntervalRef.current * 1.5, maxInterval);
+        } catch { /* ignore */ }
+      }, pollingIntervalRef.current);
+      
     } else if (!hasAnalyzing && intervalRef.current) {
-      clearInterval(intervalRef.current); intervalRef.current = null;
+      clearInterval(intervalRef.current); intervalRef.current = null; pollingIntervalRef.current = 4000; // Reset interval
     }
 
     // Per-project status polling
EOF

# 4. Add queue system for analysis
echo "Creating analysis queue implementation"
cat << 'EOF' > analysis_queue.patch
--- a/application/usecases/analysis/project_analysis_usecase.go
+++ b/application/usecases/analysis/project_analysis_usecase.go
@@ -3,6 +3,8 @@ package analysis
 import (
 	"fmt"
 	"log"
+	"sync"
+	"time"
 
 	"codeecho/domain/repositories"
 	"codeecho/infrastructure/analyzer"
@@ -10,9 +12,16 @@ import (
 	"codeecho/infrastructure/git"
 )
 
+// Global analysis queue
+var (
+	analysisQueue    = make(chan analysisJob, 10)
+	activeAnalysis   = make(map[int]bool)
+	analysisMutex    = &sync.Mutex{}
+)
+
 // ProjectAnalysisUseCase handles project analysis operations
 type ProjectAnalysisUseCase struct {
-	analyzer    *analyzer.RepositoryAnalyzer
+	analyzer     *analyzer.RepositoryAnalyzer
 	projectRepo repositories.ProjectRepository
 }
 
@@ -25,21 +34,55 @@ func NewProjectAnalysisUseCase(projectRepo repositories.ProjectRepository) *Proje
 
 	return &ProjectAnalysisUseCase{
 		analyzer:    analyzer,
-		projectRepo: projectRepo,
+		projectRepo: projectRepo, 
 	}
 }
 
+// Initialize worker
+func init() {
+	go analysisWorker()
+}
+
+type analysisJob struct {
+	projectID int
+	repoPath  string
+	sinceHash string
+	fullAnalysis bool
+}
+
+func analysisWorker() {
+	for job := range analysisQueue {
+		analysisMutex.Lock()
+		activeAnalysis[job.projectID] = true
+		analysisMutex.Unlock()
+		
+		log.Printf("Starting queued analysis for project %d", job.projectID)
+		
+		var err error
+		if job.fullAnalysis {
+			err = analyzer.AnalyzeProject(job.projectID, job.repoPath)
+		} else {
+			err = analyzer.AnalyzeProjectSince(job.projectID, job.repoPath, job.sinceHash)
+		}
+		
+		if err != nil {
+			log.Printf("Analysis failed for project %d: %v", job.projectID, err)
+		}
+		
+		analysisMutex.Lock()
+		delete(activeAnalysis, job.projectID)
+		analysisMutex.Unlock()
+		
+		// Prevent CPU hogging by adding a small delay between analyses
+		time.Sleep(500 * time.Millisecond)
+	}
+}
+
 // AnalyzeRepository analyzes a Git repository and populates the database
 func (uc *ProjectAnalysisUseCase) AnalyzeRepository(projectID int, repoPath string) error {
 	// Get project to check if it has been analyzed before
 	project, err := uc.projectRepo.GetByID(projectID)
 	if err != nil {
-		return fmt.Errorf("failed to get project: %w", err)
-	}
-
-	if project.IsAnalyzed() {
-		// Analyze only new commits since last analysis
-		return uc.analyzer.AnalyzeProjectSince(projectID, repoPath, project.LastAnalyzedHash.String())
+		return fmt.Errorf("failed to get project for analysis queue: %w", err) 
 	} else {
 		// Full analysis of the repository
 		return uc.analyzer.AnalyzeProject(projectID, repoPath)
EOF

echo ""
echo "Performance improvement suggestions prepared."
echo "Apply patches using 'git apply [patchfile]' or modify the code directly with these optimizations."
echo ""
echo "Additional recommendations:"
echo "1. Add resource monitoring to detect when analysis is using too much CPU/memory"
echo "2. Consider adding timeouts to git operations to prevent hung processes"
echo "3. Add pagination to repository analysis to process commits in batches"
echo "4. Add an option for users to limit analysis depth for large repositories"
echo "5. Monitor and log resource usage during analysis for further optimization"